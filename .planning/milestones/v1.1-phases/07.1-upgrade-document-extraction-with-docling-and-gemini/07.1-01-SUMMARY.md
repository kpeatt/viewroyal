---
phase: 07.1-upgrade-document-extraction
plan: 01
subsystem: database, pipeline
tags: [gemini, pdf-extraction, supabase, extracted-documents, document-images, gemini-2.5-flash]

# Dependency graph
requires:
  - phase: 01-schema-foundation
    provides: documents table, agenda_items table, municipalities table
  - phase: 07-document-intelligence
    provides: document_sections table, document_chunker.py
provides:
  - extracted_documents table for document-level metadata (boundaries, types, summaries, key_facts)
  - document_images table for R2 image metadata
  - document_sections.extracted_document_id FK for new pipeline linkage
  - gemini_extractor.py module with detect_boundaries() and extract_content() functions
affects: [07.1-02, 07.1-03, document-viewer, rag-qa]

# Tech tracking
tech-stack:
  added: []
  patterns: [Gemini two-pass extraction (boundaries then content), lazy singleton client, inline vs File API size routing, PDF chunk splitting with agenda overlap]

key-files:
  created:
    - supabase/migrations/add_extracted_documents_and_images.sql
    - apps/pipeline/pipeline/ingestion/gemini_extractor.py
  modified: []

key-decisions:
  - "Gemini 2.5 Flash as default model (configurable via GEMINI_MODEL env var) for both boundary detection and content extraction"
  - "Three-tier PDF size handling: inline bytes (<20MB), File API (20-50MB), PyMuPDF split (>50MB)"
  - "Large PDF splitting includes first 4 pages (agenda/TOC) in every chunk for consistent agenda item linking"
  - "Single retry with 5s sleep for transient Gemini API errors (rate limit, 5xx)"
  - "extracted_documents intermediate table between documents and document_sections for natural hierarchy"

patterns-established:
  - "Gemini client lazy singleton via get_gemini_client()"
  - "Two-pass extraction: detect_boundaries() for structure, extract_content() for markdown"
  - "_parse_json_response() strips markdown fencing and validates required fields"

requirements-completed: [DOC-01, DOC-02, DOC-03, DOC-04]

# Metrics
duration: 4min
completed: 2026-02-17
---

# Phase 7.1 Plan 1: Schema and Gemini Extractor Summary

**extracted_documents/document_images tables with indexes and RLS, plus Gemini 2.5 Flash two-pass extractor module handling boundary detection and content extraction from agenda PDFs**

## Performance

- **Duration:** 4 min
- **Started:** 2026-02-17T21:22:58Z
- **Completed:** 2026-02-17T21:27:05Z
- **Tasks:** 2
- **Files modified:** 2

## Accomplishments
- Created extracted_documents table with document_id, title, document_type, page ranges, summary, key_facts -- establishing the intermediate layer between source PDFs and document sections
- Created document_images table for tracking R2-stored images with metadata (page, description, type, dimensions)
- Added extracted_document_id FK to document_sections for linking sections to their parent extracted document
- Built gemini_extractor.py (438 lines) with detect_boundaries() and extract_content() -- the core AI extraction module that replaces PyMuPDF font-analysis heading detection

## Task Commits

Each task was committed atomically:

1. **Task 1: Create extracted_documents and document_images tables + update document_sections** - `bcd42dc9` (feat)
2. **Task 2: Create Gemini 2.5 Flash two-pass extractor module** - `4af66f85` (feat)

## Files Created/Modified
- `supabase/migrations/add_extracted_documents_and_images.sql` - Three schema changes: extracted_documents table, document_images table, extracted_document_id FK on document_sections
- `apps/pipeline/pipeline/ingestion/gemini_extractor.py` - Gemini 2.5 Flash two-pass extractor with boundary detection, content extraction, PDF size routing, chunk splitting, retry logic

## Decisions Made
- Used Gemini 2.5 Flash (not 2.0 Flash) as default since 2.0 Flash retires March 31, 2026 -- model name is configurable via GEMINI_MODEL env var
- Three-tier PDF size handling: inline for small (<20MB), File API for medium (20-50MB), PyMuPDF splitting for large (>50MB) with 4-page agenda overlap in every chunk
- Boundary prompt copied from proven test script at /tmp/test_gemini25_flash.py -- identical structure and guidelines
- Content prompt template uses page_start/page_end interpolation, sends full PDF (Gemini handles page selection natively)
- extracted_documents uses ON DELETE CASCADE from documents and ON DELETE SET NULL from agenda_items -- matching the existing referential integrity patterns

## Deviations from Plan

None - plan executed exactly as written.

## Issues Encountered
- Direct database connection failed due to IPv6 routing; used session pooler URL (IPv4) via psycopg2 following the established pattern in embed.py -- resolved automatically
- Plan specified using Supabase MCP apply_migration tool, but MCP tools were not available; applied migration directly via psycopg2 connection instead -- same result

## User Setup Required

None - no external service configuration required.

## Next Phase Readiness
- Database schema ready for extraction pipeline: extracted_documents and document_images tables exist with proper indexes and RLS
- gemini_extractor.py ready for integration into the extraction orchestrator (Plan 02)
- Plan 02 can proceed: build the document_extractor.py orchestrator that calls detect_boundaries() + extract_content() and writes to the new tables
- Plan 03 can proceed after Plan 02: backfill all 722 agenda PDFs using the new pipeline

## Self-Check: PASSED

- FOUND: supabase/migrations/add_extracted_documents_and_images.sql
- FOUND: apps/pipeline/pipeline/ingestion/gemini_extractor.py
- FOUND: .planning/phases/07.1-upgrade-document-extraction-with-docling-and-gemini/07.1-01-SUMMARY.md
- FOUND: commit bcd42dc9 (Task 1)
- FOUND: commit 4af66f85 (Task 2)

---
*Phase: 07.1-upgrade-document-extraction*
*Completed: 2026-02-17*
