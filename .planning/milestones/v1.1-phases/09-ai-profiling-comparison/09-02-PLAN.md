---
phase: 09-ai-profiling-comparison
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/pipeline/pipeline/profiling/__init__.py
  - apps/pipeline/pipeline/profiling/stance_generator.py
  - apps/pipeline/main.py
  - apps/pipeline/pipeline/orchestrator.py
autonomous: true
requirements: [PROF-04, PROF-05]

must_haves:
  truths:
    - "Stance generation produces AI summaries grounded in real evidence (key statements, votes, motions)"
    - "Each stance has a position score, confidence level, and evidence quotes"
    - "Confidence thresholds are enforced: <3 statements = low, 3-7 = medium, 8+ = high"
    - "Low-data topics include hedged language per user decision"
    - "Pipeline can be run via --generate-stances flag"
  artifacts:
    - path: "apps/pipeline/pipeline/profiling/stance_generator.py"
      provides: "Gemini-powered stance generation for councillor+topic pairs"
      min_lines: 100
    - path: "apps/pipeline/main.py"
      provides: "--generate-stances CLI flag"
      contains: "generate-stances"
  key_links:
    - from: "apps/pipeline/pipeline/profiling/stance_generator.py"
      to: "Gemini API"
      via: "google.genai client"
      pattern: "genai|GenerativeModel"
    - from: "apps/pipeline/pipeline/profiling/stance_generator.py"
      to: "councillor_stances table"
      via: "Supabase insert/upsert"
      pattern: "councillor_stances"
---

<objective>
Create the Python pipeline module that generates AI stance summaries for each councillor per topic using Gemini, grounded in key statements, votes, and motions evidence.

Purpose: Pre-computes stance data so the profile page can serve it instantly without real-time AI calls.
Output: Pipeline module + CLI flag `--generate-stances` that populates the councillor_stances table.
</objective>

<execution_context>
@/Users/kyle/.claude/get-shit-done/workflows/execute-plan.md
@/Users/kyle/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-ai-profiling-comparison/09-RESEARCH.md
@apps/pipeline/pipeline/ingestion/gemini_extractor.py
@apps/pipeline/pipeline/ingestion/ai_refiner.py
@apps/pipeline/main.py
@apps/pipeline/pipeline/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create stance_generator.py module</name>
  <files>apps/pipeline/pipeline/profiling/__init__.py, apps/pipeline/pipeline/profiling/stance_generator.py</files>
  <action>
Create `apps/pipeline/pipeline/profiling/` package with `__init__.py` (empty) and `stance_generator.py`.

**stance_generator.py** implements:

1. `generate_all_stances(supabase_client, gemini_model=None, person_id=None)` -- main entry point:
   - If person_id specified, generate stances for only that person. Otherwise, all councillors (is_councillor=true).
   - For each councillor, for each of the 8 topics:
     a. Gather evidence: query key_statements joined to agenda_items where `normalize_category_to_topic(category) = topic` and `person_id = councillor.id`. Also query votes for this person on motions whose agenda_item category matches.
     b. Format evidence text (max ~15 key statements + 10 relevant votes to stay within context window)
     c. Call Gemini with structured output prompt (from research stance prompt pattern)
     d. Parse JSON response
     e. Upsert into councillor_stances table
   - Rate limit: 1-second delay between Gemini calls to respect rate limits
   - Skip topics with zero evidence (no key_statements AND no votes for that topic)

2. `_gather_evidence(supabase, person_id, topic)` -- returns dict with:
   - `key_statements`: list of {text, meeting_date, segment_id, agenda_item_title}
   - `votes`: list of {vote, motion_text, result, meeting_date}
   - `statement_count`: total evidence items

3. `_build_prompt(person_name, topic, evidence)` -- builds the Gemini prompt:
   - Uses the stance prompt pattern from research
   - Includes evidence text
   - Requests JSON response with position, position_score, summary, key_quotes, confidence_note
   - Enforces confidence qualifier language rules (<3 items = "Limited data suggests...")

4. `_determine_confidence(statement_count)` -- returns 'high' (8+), 'medium' (3-7), 'low' (<3)

5. `_upsert_stance(supabase, person_id, topic, result, statement_count)` -- upserts into councillor_stances with ON CONFLICT (person_id, topic) DO UPDATE.

**Gemini client:** Use the lazy singleton pattern from `gemini_extractor.py` -- `get_gemini_client()`. Import it or replicate the pattern. Use model "gemini-2.5-flash" (configurable via env var GEMINI_MODEL).

**Category normalization in Python:** The normalize_category_to_topic function is in SQL. For gathering evidence, use a SQL query that calls the function: `SELECT ks.*, normalize_category_to_topic(ai.category) as topic FROM key_statements ks JOIN agenda_items ai ON ks.agenda_item_id = ai.id WHERE ks.person_id = $1 AND normalize_category_to_topic(ai.category) = $2`.

Or alternatively, query all key_statements for a person and group by topic in Python using a matching Python implementation of the normalization logic. The SQL approach is cleaner.

Print progress: `[Stances] Processing {person_name} - {topic} ({n} evidence items)...`
Print summary at end: `[Stances] Generated {n} stances for {m} councillors`
  </action>
  <verify>Run `cd apps/pipeline && python -c "from pipeline.profiling.stance_generator import generate_all_stances; print('Import OK')"` to verify the module imports correctly.</verify>
  <done>stance_generator.py module imports cleanly, has generate_all_stances entry point, _gather_evidence, _build_prompt, _determine_confidence, and _upsert_stance functions.</done>
</task>

<task type="auto">
  <name>Task 2: Wire stance generation into pipeline CLI and orchestrator</name>
  <files>apps/pipeline/main.py, apps/pipeline/pipeline/orchestrator.py</files>
  <action>
1. **main.py:** Add `--generate-stances` argument:
```python
parser.add_argument(
    "--generate-stances",
    action="store_true",
    help="Generate AI stance summaries for all councillors using Gemini. "
         "Use --target to generate for a specific person ID only.",
)
```

Add handler block (after the existing elif chain, before the else):
```python
elif args.generate_stances:
    print("\n--- Generating Councillor Stance Summaries ---")
    app.generate_stances(person_id=args.target)
```

2. **orchestrator.py:** Add `generate_stances(self, person_id=None)` method to the Archiver class:
```python
def generate_stances(self, person_id=None):
    from pipeline.profiling.stance_generator import generate_all_stances
    generate_all_stances(self.supabase, person_id=person_id)
```

The lazy import avoids loading Gemini SDK unless needed.
  </action>
  <verify>Run `cd apps/pipeline && uv run python main.py --help` and confirm `--generate-stances` appears in the help output.</verify>
  <done>--generate-stances flag appears in CLI help. Running it would invoke generate_all_stances via the Archiver.</done>
</task>

</tasks>

<verification>
1. `from pipeline.profiling.stance_generator import generate_all_stances` imports without error
2. `--generate-stances` appears in `python main.py --help`
3. Code handles edge cases: zero-evidence topics (skip), Gemini errors (log + continue), malformed JSON (retry once)
</verification>

<success_criteria>
- Stance generator module exists with Gemini integration
- Evidence gathering queries key_statements and votes, filtered by normalized topic
- Confidence thresholds enforced: <3=low, 3-7=medium, 8+=high
- Pipeline CLI accepts --generate-stances flag
- Stances upserted with ON CONFLICT handling for idempotency
</success_criteria>

<output>
After completion, create `.planning/phases/09-ai-profiling-comparison/09-02-SUMMARY.md`
</output>
