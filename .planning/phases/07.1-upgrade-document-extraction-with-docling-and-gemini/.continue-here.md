---
phase: 07.1-upgrade-document-extraction-with-docling-and-gemini
task: 2
total_tasks: 2
status: paused
last_updated: 2026-02-17T08:00:00.000Z
---

<current_state>
Phase 07.1 execution: Plans 01 and 02 fully complete. Plan 03 task 1 complete (backfill CLI), task 2 is a human-verify checkpoint â€” paused by user request.

Batch API implemented and 5-meeting test completed successfully. Quality review revealed two bugs (overlapping boundaries + double insertion) â€” both fixed and committed (6fdcbfb7). Test data wiped, DB clean, ready for full 711-meeting backfill.
</current_state>

<completed_work>

- Plan 07.1-01 (Wave 1): Schema + Gemini extractor â€” DONE
  - Created `extracted_documents` and `document_images` tables via Supabase migration
  - Added `extracted_document_id` FK to `document_sections`
  - Created `gemini_extractor.py`: two-pass extraction with boundary detection + content extraction
  - Commits: bcd42dc9, 4af66f85, 45f9eb07

- Plan 07.1-02 (Wave 2): Image extractor + pipeline integration â€” DONE
  - Created `image_extractor.py`, `document_extractor.py`
  - Updated `ingester.py` and `orchestrator.py` for new pipeline
  - Removed Docling, added boto3
  - Commits: 3adf2a78, fd9e419a, 52eef13a

- Plan 07.1-03 Task 1: Backfill CLI â€” DONE
  - `--extract-documents` CLI flag with `--limit` and `--force`
  - Commit: b7a56c73

- Batch API implementation â€” DONE
  - Created `batch_extractor.py` (~1100 lines): 3-phase pipeline (boundary batch â†’ content batch â†’ DB insertion)
  - 5-meeting test completed: 164 boundaries, 452 extracted docs, 1,668 sections (before dedup)

- Quality fixes â€” DONE
  - Boundary prompt updated: explicit non-overlapping page range requirement
  - `_dedup_overlapping_boundaries()`: removes parent boundaries containing children
  - `insert_meeting_results()`: cleans up existing data before inserting
  - Test data wiped from DB, state file deleted
  - Commit: 6fdcbfb7

</completed_work>

<remaining_work>

1. **Run full 711-meeting backfill** via Gemini Batch API
   ```bash
   cd apps/pipeline && uv run python main.py --extract-documents --batch
   ```
2. Complete Plan 03 human-verify checkpoint (approve extraction quality)
3. Phase verification

</remaining_work>

<decisions_made>

- Gemini PDF processing limit is 50MB (not 2GB)
- Inline data payload limit raised to 100MB, PDFs under 50MB use inline bytes
- Adaptive PDF splitting for >50MB PDFs
- Fallback to old PyMuPDF chunker for Gemini failures
- R2 image uploads gracefully degrade if credentials missing
- Full backfill uses Gemini Batch API (3-phase: boundaries â†’ content â†’ DB insertion)
- Boundary prompt requires non-overlapping page ranges
- Parent boundaries containing children are automatically removed by dedup
- DB cleanup runs before insertion to prevent duplicates on re-runs

</decisions_made>

<blockers>
None â€” ready for full backfill.
</blockers>

<context>
Database state: extracted_documents, document_sections (with extracted_document_id), and document_images tables are all empty. batch_extraction_state.json deleted. Clean slate.

Key files:
- apps/pipeline/pipeline/ingestion/gemini_extractor.py â€” core Gemini extraction + boundary dedup
- apps/pipeline/pipeline/ingestion/batch_extractor.py â€” Batch API pipeline (NEW)
- apps/pipeline/pipeline/ingestion/document_extractor.py â€” sync orchestrator
- apps/pipeline/pipeline/orchestrator.py â€” backfill_extracted_documents method
- apps/pipeline/main.py â€” CLI entry point
</context>

<next_action>
1. âœ… Batch API implemented (batch_extractor.py)
2. âœ… 5-meeting test completed successfully
3. âœ… Quality review: found overlapping boundaries + double insertion bugs
4. âœ… Both bugs fixed, test data wiped, committed (6fdcbfb7)
5. ðŸ”œ Run full 711-meeting backfill
6. Complete Plan 03 checkpoint and phase verification
</next_action>
