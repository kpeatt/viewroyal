---
phase: 07.1-upgrade-document-extraction-with-docling-and-gemini
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/pipeline/pipeline/ingestion/gemini_boundary.py
  - apps/pipeline/pyproject.toml
autonomous: true
requirements:
  - DOC-04

must_haves:
  truths:
    - "Gemini 2.0 Flash can receive a PDF and return structured JSON identifying document boundaries within it"
    - "PDFs over 50MB are uploaded via the File API rather than sent inline"
    - "PDFs over 1000 pages are split into overlapping chunks with agenda pages prepended"
    - "The output token limit (8192) is detected and handled gracefully"
    - "extracted_documents and document_images tables exist in Supabase"
    - "document_sections has an extracted_document_id FK column"
  artifacts:
    - path: "apps/pipeline/pipeline/ingestion/gemini_boundary.py"
      provides: "Gemini boundary detection module"
      min_lines: 150
  key_links:
    - from: "apps/pipeline/pipeline/ingestion/gemini_boundary.py"
      to: "google.genai API"
      via: "client.models.generate_content with PDF bytes"
      pattern: "generate_content"
---

<objective>
Create the database schema foundation and the Gemini boundary detection module that identifies individual documents within agenda package PDFs.

Purpose: The Gemini module is the first step in the three-tool pipeline. It receives a full agenda PDF and returns structured JSON with document boundaries (title, page_start, page_end, type, agenda_item, summary, key_facts, image descriptions). The schema adds the `extracted_documents` intermediate table and `document_images` table needed by downstream plans.

Output: `gemini_boundary.py` module with proven Gemini integration, database migration applied, `boto3` added to dependencies.
</objective>

<execution_context>
@/Users/kyle/.claude/get-shit-done/workflows/execute-plan.md
@/Users/kyle/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07.1-upgrade-document-extraction-with-docling-and-gemini/07.1-CONTEXT.md
@.planning/phases/07.1-upgrade-document-extraction-with-docling-and-gemini/07.1-RESEARCH.md
@apps/pipeline/pipeline/ingestion/ingester.py
@apps/pipeline/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database schema migration and dependency update</name>
  <files>apps/pipeline/pyproject.toml</files>
  <action>
1. Apply a Supabase migration (use `mcp__supabase__apply_migration`) to create:

```sql
-- extracted_documents: individual documents identified within an agenda package PDF
CREATE TABLE extracted_documents (
    id bigint generated by default as identity primary key,
    document_id bigint REFERENCES documents(id) ON DELETE CASCADE NOT NULL,
    agenda_item_id bigint REFERENCES agenda_items(id) ON DELETE SET NULL,
    title text NOT NULL,
    document_type text NOT NULL DEFAULT 'other',
    page_start integer,
    page_end integer,
    summary text,
    key_facts jsonb,
    municipality_id bigint REFERENCES municipalities(id) DEFAULT 1,
    created_at timestamptz DEFAULT timezone('utc'::text, now()) NOT NULL
);

-- Add extracted_document_id FK to document_sections
ALTER TABLE document_sections
    ADD COLUMN extracted_document_id bigint REFERENCES extracted_documents(id) ON DELETE CASCADE;

-- document_images: image metadata (actual images stored in R2)
CREATE TABLE document_images (
    id bigint generated by default as identity primary key,
    extracted_document_id bigint REFERENCES extracted_documents(id) ON DELETE CASCADE NOT NULL,
    document_id bigint REFERENCES documents(id) ON DELETE CASCADE NOT NULL,
    page_number integer NOT NULL,
    description text,
    image_type text DEFAULT 'other',
    width integer,
    height integer,
    format text,
    r2_key text,
    r2_url text,
    municipality_id bigint REFERENCES municipalities(id) DEFAULT 1,
    created_at timestamptz DEFAULT timezone('utc'::text, now()) NOT NULL
);

-- Indexes for common query patterns
CREATE INDEX idx_extracted_documents_document_id ON extracted_documents(document_id);
CREATE INDEX idx_extracted_documents_agenda_item_id ON extracted_documents(agenda_item_id);
CREATE INDEX idx_extracted_documents_document_type ON extracted_documents(document_type);
CREATE INDEX idx_document_sections_extracted_document_id ON document_sections(extracted_document_id);
CREATE INDEX idx_document_images_extracted_document_id ON document_images(extracted_document_id);

-- Enable RLS (required by Supabase security advisor)
ALTER TABLE extracted_documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE document_images ENABLE ROW LEVEL SECURITY;

-- Public read policies (same pattern as other tables)
CREATE POLICY "Public read access" ON extracted_documents FOR SELECT USING (true);
CREATE POLICY "Public read access" ON document_images FOR SELECT USING (true);
```

2. Add `boto3>=1.35.0` to `apps/pipeline/pyproject.toml` dependencies (needed for R2 S3-compatible uploads in Plan 02).
  </action>
  <verify>
Run `mcp__supabase__list_tables` to confirm `extracted_documents` and `document_images` tables exist. Run `mcp__supabase__execute_sql` with `SELECT column_name FROM information_schema.columns WHERE table_name = 'document_sections' AND column_name = 'extracted_document_id'` to confirm the new FK column exists. Check pyproject.toml contains boto3.
  </verify>
  <done>
Three new database objects exist: `extracted_documents` table, `document_images` table, and `extracted_document_id` column on `document_sections`. All have indexes and RLS policies. `boto3` is in pyproject.toml.
  </done>
</task>

<task type="auto">
  <name>Task 2: Gemini boundary detection module</name>
  <files>apps/pipeline/pipeline/ingestion/gemini_boundary.py</files>
  <action>
Create `apps/pipeline/pipeline/ingestion/gemini_boundary.py` implementing:

**Constants/Config:**
- `GEMINI_MODEL = "gemini-2.0-flash"` (configurable via env var `GEMINI_BOUNDARY_MODEL`)
- `MAX_INLINE_SIZE = 40 * 1024 * 1024` (40MB safety margin for 50MB limit)
- `MAX_PAGES_PER_CHUNK = 500` (for chunking very large PDFs)
- `CHUNK_OVERLAP = 2` (pages of overlap between chunks)

**Boundary detection prompt** (from RESEARCH.md proven working pattern):
A system prompt that instructs Gemini to analyze a municipal council meeting agenda package PDF and return a JSON array of document boundary objects. Each object has: `title` (str), `page_start` (int), `page_end` (int), `type` (one of: agenda, minutes, staff_report, delegation, correspondence, appendix, table, other), `agenda_item` (str or null), `summary` (str), `key_facts` (list[str]), `images` (list of {page, description, type}).

Guidelines in prompt:
- Be precise about page boundaries
- Each distinct document should be its own entry
- Don't split sub-sections within a single document
- key_facts: capture dollar amounts, dates, addresses, decisions
- images: describe meaningful charts, maps, diagrams, renderings (skip logos/signatures)
- Return ONLY a JSON array, no other text

**Main function: `detect_boundaries(pdf_path: str, api_key: str) -> list[dict]`**

Logic:
1. Read PDF file, check file size and page count (use `fitz.open` for page count)
2. If file_size < MAX_INLINE_SIZE and pages < 1000:
   - Send entire PDF inline via `types.Part.from_bytes(data=pdf_bytes, mime_type="application/pdf")`
3. If file_size >= MAX_INLINE_SIZE but pages < 1000:
   - Upload via `client.files.upload(file=pdf_path)`, then send the file reference
4. If pages >= 1000:
   - Split into chunks of MAX_PAGES_PER_CHUNK with CHUNK_OVERLAP
   - For each chunk: extract those pages into a temporary PDF using PyMuPDF (`fitz.open()`, `doc.select()`, `doc.save()`)
   - Prepend the first 5 pages (agenda/TOC) to each chunk so Gemini can always link to agenda items
   - Send each chunk, merge results, adjust page numbers from chunk offsets
5. Parse JSON response — handle both clean JSON and markdown-fenced JSON (```json...```)
6. Check `response.candidates[0].finish_reason` — if `MAX_TOKENS`, log a warning (output was truncated)
7. Return list of boundary dicts

**Helper: `_parse_gemini_response(response) -> list[dict]`**
- Extract text from response
- Strip markdown code fences if present
- Parse JSON
- Validate each entry has required fields (title, page_start, page_end, type)
- Log warnings for entries with missing optional fields

**Helper: `_merge_chunk_results(chunks: list[list[dict]], chunk_starts: list[int]) -> list[dict]`**
- Adjust page numbers by chunk offset
- De-duplicate documents that appear in overlap regions (match by title + page proximity)

Use `google.genai` client (already a dependency). Import pattern:
```python
from google import genai
from google.genai import types
```

Add basic retry logic: if the API call fails with a retryable error (429, 500, 503), retry up to 3 times with exponential backoff (2s, 4s, 8s).

Log key metrics: PDF page count, file size, number of documents detected, processing time.
  </action>
  <verify>
Run `cd /Users/kyle/development/viewroyal/apps/pipeline && uv run python -c "from pipeline.ingestion.gemini_boundary import detect_boundaries; print('import OK')"` to confirm the module imports correctly. Verify the file exists and has the expected functions.
  </verify>
  <done>
`gemini_boundary.py` module exists with `detect_boundaries()` function that handles: inline PDF sending (< 40MB), File API upload (40-100MB+), page chunking (1000+ pages), JSON response parsing with code fence stripping, retry logic, and `MAX_TOKENS` finish reason detection. Model name is configurable via env var.
  </done>
</task>

</tasks>

<verification>
- `extracted_documents` table exists with all columns (document_id, agenda_item_id, title, document_type, page_start, page_end, summary, key_facts, municipality_id)
- `document_images` table exists with all columns (extracted_document_id, document_id, page_number, description, image_type, width, height, format, r2_key, r2_url)
- `document_sections.extracted_document_id` FK column exists
- All tables have RLS enabled with public read policies
- `gemini_boundary.py` imports cleanly
- `detect_boundaries()` signature accepts (pdf_path, api_key) and returns list[dict]
- Module handles PDFs of any size (inline, File API, chunked)
- boto3 is in pyproject.toml dependencies
</verification>

<success_criteria>
The schema is extended with the intermediate `extracted_documents` layer and image metadata table. The Gemini boundary detection module can receive any agenda PDF and return structured boundary data. The module handles size limits, output token truncation, and retry logic. All existing data remains untouched (no destructive changes yet).
</success_criteria>

<output>
After completion, create `.planning/phases/07.1-upgrade-document-extraction-with-docling-and-gemini/07.1-01-SUMMARY.md`
</output>
